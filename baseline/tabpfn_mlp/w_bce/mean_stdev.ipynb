{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log files:\n",
      " - tabpfn_mlp_bce_seed0.log\n",
      " - tabpfn_mlp_bce_seed2.log\n",
      " - tabpfn_mlp_bce_seed12.log\n",
      " - tabpfn_mlp_bce_seed15.log\n",
      " - tabpfn_mlp_bce_seed21.log\n",
      "\n",
      "Per-run results (from LAST [TEST] block):\n",
      "                        file  seed     auc    bacc  sens20  sens40  sens60\n",
      "0   tabpfn_mlp_bce_seed0.log     0  0.7210  0.6654  0.9575  0.8523  0.7472\n",
      "1   tabpfn_mlp_bce_seed2.log     2  0.6717  0.6440  0.9485  0.8814  0.0022\n",
      "2  tabpfn_mlp_bce_seed12.log    12  0.7162  0.6620  0.9553  0.8859  0.7383\n",
      "3  tabpfn_mlp_bce_seed15.log    15  0.7061  0.6542  0.9508  0.8300  0.7136\n",
      "4  tabpfn_mlp_bce_seed21.log    21  0.7146  0.6396  0.9508  0.8949  0.6846\n",
      "\n",
      "Summary (mean ± std) across seeds:\n",
      "          mean     std\n",
      "auc     0.7059  0.0199\n",
      "bacc    0.6530  0.0111\n",
      "sens20  0.9526  0.0037\n",
      "sens40  0.8689  0.0270\n",
      "sens60  0.5772  0.3223\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# your .log files\n",
    "# LOG_DIR = \"*.log\"\n",
    "log_files = [\n",
    "    \"tabpfn_mlp_bce_seed0.log\",\n",
    "    \"tabpfn_mlp_bce_seed2.log\",\n",
    "    \"tabpfn_mlp_bce_seed12.log\",\n",
    "    \"tabpfn_mlp_bce_seed15.log\",\n",
    "    \"tabpfn_mlp_bce_seed21.log\",\n",
    "]\n",
    "\n",
    "# regex patterns to capture the values\n",
    "patterns = {\n",
    "    \"seed\": r\"Running with seed:\\s*(\\d+)\",\n",
    "    \"auc\": r\"ROC AUC:\\s*([0-9.]+)\",\n",
    "    \"bacc\": r\"Balanced Accuracy:\\s*([0-9.]+)\",\n",
    "    \"sens_spec20\": r\"Spec 20% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec40\": r\"Spec 40% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec60\": r\"Spec 60% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "}\n",
    "\n",
    "# store results per seed\n",
    "all_results = []\n",
    "\n",
    "print(\"Using log files:\")\n",
    "for f in log_files:\n",
    "    print(\" -\", f)\n",
    "\n",
    "# Regex patterns (handles the unicode arrow \"→\")\n",
    "pat_seed = re.compile(r\"Running with seed:\\s*(\\d+)\")\n",
    "pat_auc = re.compile(r\"ROC AUC:\\s*([0-9.]+)\")\n",
    "pat_bacc = re.compile(r\"Balanced Accuracy:\\s*([0-9.]+)\")\n",
    "pat_spec20 = re.compile(r\"Spec\\s*20%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40 = re.compile(r\"Spec\\s*40%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60 = re.compile(r\"Spec\\s*60%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "# (Optional) fallback patterns if your logs sometimes use \"->\" instead of \"→\"\n",
    "pat_spec20_fallback = re.compile(r\"Spec\\s*20%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40_fallback = re.compile(r\"Spec\\s*40%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60_fallback = re.compile(r\"Spec\\s*60%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "def extract_from_last_test_block(text: str):\n",
    "    \"\"\"\n",
    "    Split by '[TEST]' and parse metrics from the last block only.\n",
    "    Returns dict with seed, auc, bacc, sens20/40/60 (sensitivities).\n",
    "    \"\"\"\n",
    "    parts = re.split(r\"\\[TEST\\]\", text)\n",
    "    last_block = parts[-1] if parts else text  # if no [TEST], use whole text\n",
    "\n",
    "    # get seed from anywhere in file (first occurrence)\n",
    "    seed_m = pat_seed.search(text)\n",
    "    seed = int(seed_m.group(1)) if seed_m else None\n",
    "\n",
    "    # pull metrics from the last block\n",
    "    def _grab(pat, block, fallback=None):\n",
    "        m = pat.search(block)\n",
    "        if (not m) and fallback:\n",
    "            m = fallback.search(block)\n",
    "        return m\n",
    "\n",
    "    auc_m = pat_auc.search(last_block)\n",
    "    bacc_m = pat_bacc.search(last_block)\n",
    "\n",
    "    s20_m = _grab(pat_spec20, last_block, pat_spec20_fallback)\n",
    "    s40_m = _grab(pat_spec40, last_block, pat_spec40_fallback)\n",
    "    s60_m = _grab(pat_spec60, last_block, pat_spec60_fallback)\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"auc\": float(auc_m.group(1)) if auc_m else None,\n",
    "        \"bacc\": float(bacc_m.group(1)) if bacc_m else None,\n",
    "        \"sens20\": float(s20_m.group(1)) if s20_m else None,\n",
    "        \"sens40\": float(s40_m.group(1)) if s40_m else None,\n",
    "        \"sens60\": float(s60_m.group(1)) if s60_m else None,\n",
    "    }\n",
    "\n",
    "# Parse all logs\n",
    "rows = []\n",
    "for path in log_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "    row = {\"file\": path}\n",
    "    row.update(extract_from_last_test_block(txt))\n",
    "    rows.append(row)\n",
    "\n",
    "df_runs = pd.DataFrame(rows)\n",
    "print(\"\\nPer-run results (from LAST [TEST] block):\")\n",
    "print(df_runs)\n",
    "\n",
    "# Summaries\n",
    "summary = {}\n",
    "for metric in [\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\"]:\n",
    "    vals = df_runs[metric].dropna().to_numpy(dtype=float)\n",
    "    if len(vals) == 0:\n",
    "        mean, std = np.nan, np.nan\n",
    "    elif len(vals) == 1:\n",
    "        mean, std = float(vals[0]), np.nan\n",
    "    else:\n",
    "        mean, std = float(np.mean(vals)), float(np.std(vals, ddof=1))\n",
    "    summary[metric] = {\"mean\": mean, \"std\": std}\n",
    "\n",
    "df_summary = pd.DataFrame(summary).T\n",
    "print(\"\\nSummary (mean ± std) across seeds:\")\n",
    "print(df_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log files:\n",
      " - tabpfn_mlp_bce_seed0.log\n",
      " - tabpfn_mlp_bce_seed3.log\n",
      " - tabpfn_mlp_bce_seed12.log\n",
      " - tabpfn_mlp_bce_seed15.log\n",
      " - tabpfn_mlp_bce_seed21.log\n",
      "\n",
      "Per-run results (from LAST [TEST] block):\n",
      "                        file  seed     auc    bacc  sens20  sens40  sens60\n",
      "0   tabpfn_mlp_bce_seed0.log     0  0.7210  0.6654  0.9575  0.8523  0.7472\n",
      "1   tabpfn_mlp_bce_seed3.log     3  0.7160  0.6611  0.9508  0.8725  0.7025\n",
      "2  tabpfn_mlp_bce_seed12.log    12  0.7162  0.6620  0.9553  0.8859  0.7383\n",
      "3  tabpfn_mlp_bce_seed15.log    15  0.7061  0.6542  0.9508  0.8300  0.7136\n",
      "4  tabpfn_mlp_bce_seed21.log    21  0.7146  0.6396  0.9508  0.8949  0.6846\n",
      "\n",
      "Summary (mean ± std) across seeds:\n",
      "          mean     std\n",
      "auc     0.7148  0.0054\n",
      "bacc    0.6565  0.0103\n",
      "sens20  0.9530  0.0032\n",
      "sens40  0.8671  0.0262\n",
      "sens60  0.7172  0.0257\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# your .log files\n",
    "# LOG_DIR = \"*.log\"\n",
    "log_files = [\n",
    "    \"tabpfn_mlp_bce_seed0.log\",\n",
    "    \"tabpfn_mlp_bce_seed3.log\",\n",
    "    \"tabpfn_mlp_bce_seed12.log\",\n",
    "    \"tabpfn_mlp_bce_seed15.log\",\n",
    "    \"tabpfn_mlp_bce_seed21.log\",\n",
    "]\n",
    "\n",
    "# regex patterns to capture the values\n",
    "patterns = {\n",
    "    \"seed\": r\"Running with seed:\\s*(\\d+)\",\n",
    "    \"auc\": r\"ROC AUC:\\s*([0-9.]+)\",\n",
    "    \"bacc\": r\"Balanced Accuracy:\\s*([0-9.]+)\",\n",
    "    \"sens_spec20\": r\"Spec 20% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec40\": r\"Spec 40% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec60\": r\"Spec 60% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "}\n",
    "\n",
    "# store results per seed\n",
    "all_results = []\n",
    "\n",
    "print(\"Using log files:\")\n",
    "for f in log_files:\n",
    "    print(\" -\", f)\n",
    "\n",
    "# Regex patterns (handles the unicode arrow \"→\")\n",
    "pat_seed = re.compile(r\"Running with seed:\\s*(\\d+)\")\n",
    "pat_auc = re.compile(r\"ROC AUC:\\s*([0-9.]+)\")\n",
    "pat_bacc = re.compile(r\"Balanced Accuracy:\\s*([0-9.]+)\")\n",
    "pat_spec20 = re.compile(r\"Spec\\s*20%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40 = re.compile(r\"Spec\\s*40%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60 = re.compile(r\"Spec\\s*60%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "# (Optional) fallback patterns if your logs sometimes use \"->\" instead of \"→\"\n",
    "pat_spec20_fallback = re.compile(r\"Spec\\s*20%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40_fallback = re.compile(r\"Spec\\s*40%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60_fallback = re.compile(r\"Spec\\s*60%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "def extract_from_last_test_block(text: str):\n",
    "    \"\"\"\n",
    "    Split by '[TEST]' and parse metrics from the last block only.\n",
    "    Returns dict with seed, auc, bacc, sens20/40/60 (sensitivities).\n",
    "    \"\"\"\n",
    "    parts = re.split(r\"\\[TEST\\]\", text)\n",
    "    last_block = parts[-1] if parts else text  # if no [TEST], use whole text\n",
    "\n",
    "    # get seed from anywhere in file (first occurrence)\n",
    "    seed_m = pat_seed.search(text)\n",
    "    seed = int(seed_m.group(1)) if seed_m else None\n",
    "\n",
    "    # pull metrics from the last block\n",
    "    def _grab(pat, block, fallback=None):\n",
    "        m = pat.search(block)\n",
    "        if (not m) and fallback:\n",
    "            m = fallback.search(block)\n",
    "        return m\n",
    "\n",
    "    auc_m = pat_auc.search(last_block)\n",
    "    bacc_m = pat_bacc.search(last_block)\n",
    "\n",
    "    s20_m = _grab(pat_spec20, last_block, pat_spec20_fallback)\n",
    "    s40_m = _grab(pat_spec40, last_block, pat_spec40_fallback)\n",
    "    s60_m = _grab(pat_spec60, last_block, pat_spec60_fallback)\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"auc\": float(auc_m.group(1)) if auc_m else None,\n",
    "        \"bacc\": float(bacc_m.group(1)) if bacc_m else None,\n",
    "        \"sens20\": float(s20_m.group(1)) if s20_m else None,\n",
    "        \"sens40\": float(s40_m.group(1)) if s40_m else None,\n",
    "        \"sens60\": float(s60_m.group(1)) if s60_m else None,\n",
    "    }\n",
    "\n",
    "# Parse all logs\n",
    "rows = []\n",
    "for path in log_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "    row = {\"file\": path}\n",
    "    row.update(extract_from_last_test_block(txt))\n",
    "    rows.append(row)\n",
    "\n",
    "df_runs = pd.DataFrame(rows)\n",
    "print(\"\\nPer-run results (from LAST [TEST] block):\")\n",
    "print(df_runs)\n",
    "\n",
    "# Summaries\n",
    "summary = {}\n",
    "for metric in [\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\"]:\n",
    "    vals = df_runs[metric].dropna().to_numpy(dtype=float)\n",
    "    if len(vals) == 0:\n",
    "        mean, std = np.nan, np.nan\n",
    "    elif len(vals) == 1:\n",
    "        mean, std = float(vals[0]), np.nan\n",
    "    else:\n",
    "        mean, std = float(np.mean(vals)), float(np.std(vals, ddof=1))\n",
    "    summary[metric] = {\"mean\": mean, \"std\": std}\n",
    "\n",
    "df_summary = pd.DataFrame(summary).T\n",
    "print(\"\\nSummary (mean ± std) across seeds:\")\n",
    "print(df_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log files:\n",
      " - tabpfn_mlp_bce_seed0.log\n",
      " - tabpfn_mlp_bce_seed3.log\n",
      " - tabpfn_mlp_bce_seed12.log\n",
      " - tabpfn_mlp_bce_seed15.log\n",
      " - tabpfn_mlp_bce_seed21.log\n",
      "\n",
      "Per-run results (FIRST and LAST metrics blocks):\n",
      "                        file  seed  auc_first  bacc_first  sens20_first  \\\n",
      "0   tabpfn_mlp_bce_seed0.log     0     0.7242      0.6541        0.9553   \n",
      "1   tabpfn_mlp_bce_seed3.log     3     0.7375      0.6832        0.9620   \n",
      "2  tabpfn_mlp_bce_seed12.log    12     0.7212      0.6642        0.9620   \n",
      "3  tabpfn_mlp_bce_seed15.log    15     0.7324      0.6663        0.9642   \n",
      "4  tabpfn_mlp_bce_seed21.log    21     0.7227      0.6653        0.9508   \n",
      "\n",
      "   sens40_first  sens60_first  auc_last  bacc_last  sens20_last  sens40_last  \\\n",
      "0        0.8949        0.7114    0.7210     0.6654       0.9575       0.8523   \n",
      "1        0.9016        0.7696    0.7160     0.6611       0.9508       0.8725   \n",
      "2        0.9060        0.7047    0.7162     0.6620       0.9553       0.8859   \n",
      "3        0.8949        0.7293    0.7061     0.6542       0.9508       0.8300   \n",
      "4        0.8993        0.7181    0.7146     0.6396       0.9508       0.8949   \n",
      "\n",
      "   sens60_last  \n",
      "0       0.7472  \n",
      "1       0.7025  \n",
      "2       0.7383  \n",
      "3       0.7136  \n",
      "4       0.6846  \n",
      "\n",
      "Summary of FIRST metrics (mean ± std):\n",
      "                mean     std\n",
      "auc_first     0.7276  0.0070\n",
      "bacc_first    0.6666  0.0105\n",
      "sens20_first  0.9589  0.0056\n",
      "sens40_first  0.8993  0.0047\n",
      "sens60_first  0.7266  0.0257\n",
      "\n",
      "Summary of LAST metrics (mean ± std):\n",
      "               mean     std\n",
      "auc_last     0.7148  0.0054\n",
      "bacc_last    0.6565  0.0103\n",
      "sens20_last  0.9530  0.0032\n",
      "sens40_last  0.8671  0.0262\n",
      "sens60_last  0.7172  0.0257\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- your logs (manually defined) ----\n",
    "log_files = [\n",
    "    \"tabpfn_mlp_bce_seed0.log\",\n",
    "    \"tabpfn_mlp_bce_seed3.log\",\n",
    "    \"tabpfn_mlp_bce_seed12.log\",\n",
    "    \"tabpfn_mlp_bce_seed15.log\",\n",
    "    \"tabpfn_mlp_bce_seed21.log\",\n",
    "]\n",
    "\n",
    "print(\"Using log files:\")\n",
    "for f in log_files:\n",
    "    print(\" -\", f)\n",
    "\n",
    "# ---- regex patterns ----\n",
    "pat_seed   = re.compile(r\"Running with seed:\\s*(\\d+)\")\n",
    "pat_auc    = re.compile(r\"ROC AUC:\\s*([0-9.]+)\")\n",
    "pat_bacc   = re.compile(r\"Balanced Accuracy:\\s*([0-9.]+)\")\n",
    "\n",
    "def _mk_spec_pat(pct: int):\n",
    "    # unicode arrow or ASCII arrow\n",
    "    return (\n",
    "        re.compile(rf\"Spec\\s*{pct}%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\"),\n",
    "        re.compile(rf\"Spec\\s*{pct}%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "    )\n",
    "PAT_20 = _mk_spec_pat(20)\n",
    "PAT_40 = _mk_spec_pat(40)\n",
    "PAT_60 = _mk_spec_pat(60)\n",
    "\n",
    "def _grab(block: str, pats):\n",
    "    \"\"\"Try one or multiple regexes, return the first match.\"\"\"\n",
    "    if not isinstance(pats, (list, tuple)):\n",
    "        pats = (pats,)\n",
    "    for p in pats:\n",
    "        m = p.search(block)\n",
    "        if m:\n",
    "            return m\n",
    "    return None\n",
    "\n",
    "def parse_block(block: str):\n",
    "    \"\"\"Extract metrics from a contiguous metrics block.\"\"\"\n",
    "    auc_m  = _grab(block, pat_auc)\n",
    "    bacc_m = _grab(block, pat_bacc)\n",
    "    s20_m  = _grab(block, PAT_20)\n",
    "    s40_m  = _grab(block, PAT_40)\n",
    "    s60_m  = _grab(block, PAT_60)\n",
    "\n",
    "    return {\n",
    "        \"auc\":    float(auc_m.group(1))  if auc_m else None,\n",
    "        \"bacc\":   float(bacc_m.group(1)) if bacc_m else None,\n",
    "        \"sens20\": float(s20_m.group(1))  if s20_m else None,\n",
    "        \"sens40\": float(s40_m.group(1))  if s40_m else None,\n",
    "        \"sens60\": float(s60_m.group(1))  if s60_m else None,\n",
    "    }\n",
    "\n",
    "def find_metric_blocks(text: str):\n",
    "    \"\"\"\n",
    "    Locate all 'ROC AUC:' occurrences and slice the text into metric blocks.\n",
    "    Each block starts at a 'ROC AUC:' line and goes up to the next 'ROC AUC:' (or EOF).\n",
    "    Returns a list of dicts (parsed metrics) in file order.\n",
    "    \"\"\"\n",
    "    starts = [m.start() for m in pat_auc.finditer(text)]\n",
    "    if not starts:\n",
    "        return []\n",
    "\n",
    "    blocks = []\n",
    "    for i, s in enumerate(starts):\n",
    "        e = starts[i + 1] if (i + 1) < len(starts) else len(text)\n",
    "        chunk = text[s:e]\n",
    "        metrics = parse_block(chunk)\n",
    "        # keep only reasonably complete blocks (has auc or bacc at least)\n",
    "        if any(metrics.get(k) is not None for k in (\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\")):\n",
    "            blocks.append(metrics)\n",
    "    return blocks\n",
    "\n",
    "# ---- parse all logs: take FIRST and LAST metric block ----\n",
    "rows = []\n",
    "for path in log_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "\n",
    "    seed_m = pat_seed.search(txt)\n",
    "    seed = int(seed_m.group(1)) if seed_m else None\n",
    "\n",
    "    blocks = find_metric_blocks(txt)\n",
    "\n",
    "    first = blocks[0] if blocks else {}\n",
    "    last  = blocks[-1] if blocks else {}\n",
    "\n",
    "    row = {\n",
    "        \"file\": path,\n",
    "        \"seed\": seed,\n",
    "        # first block\n",
    "        \"auc_first\":    first.get(\"auc\"),\n",
    "        \"bacc_first\":   first.get(\"bacc\"),\n",
    "        \"sens20_first\": first.get(\"sens20\"),\n",
    "        \"sens40_first\": first.get(\"sens40\"),\n",
    "        \"sens60_first\": first.get(\"sens60\"),\n",
    "        # last block\n",
    "        \"auc_last\":    last.get(\"auc\"),\n",
    "        \"bacc_last\":   last.get(\"bacc\"),\n",
    "        \"sens20_last\": last.get(\"sens20\"),\n",
    "        \"sens40_last\": last.get(\"sens40\"),\n",
    "        \"sens60_last\": last.get(\"sens60\"),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df_runs = pd.DataFrame(rows)\n",
    "print(\"\\nPer-run results (FIRST and LAST metrics blocks):\")\n",
    "print(df_runs)\n",
    "\n",
    "# ---- summarize first vs last separately ----\n",
    "def summarize(df, suffix: str):\n",
    "    out = {}\n",
    "    for metric in [\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\"]:\n",
    "        col = f\"{metric}_{suffix}\"\n",
    "        vals = df[col].dropna().to_numpy(dtype=float)\n",
    "        if len(vals) == 0:\n",
    "            mean, std = np.nan, np.nan\n",
    "        elif len(vals) == 1:\n",
    "            mean, std = float(vals[0]), np.nan\n",
    "        else:\n",
    "            mean, std = float(np.mean(vals)), float(np.std(vals, ddof=1))\n",
    "        out[col] = {\"mean\": mean, \"std\": std}\n",
    "    return pd.DataFrame(out).T\n",
    "\n",
    "df_summary_first = summarize(df_runs, \"first\")\n",
    "df_summary_last  = summarize(df_runs, \"last\")\n",
    "\n",
    "print(\"\\nSummary of FIRST metrics (mean ± std):\")\n",
    "print(df_summary_first.round(4))\n",
    "\n",
    "print(\"\\nSummary of LAST metrics (mean ± std):\")\n",
    "print(df_summary_last.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
