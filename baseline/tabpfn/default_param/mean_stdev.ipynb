{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mean     std\n",
      "auc     0.7254  0.0044\n",
      "bacc    0.6628  0.0049\n",
      "sens20  0.9597  0.0065\n",
      "sens40  0.8980  0.0049\n",
      "sens60  0.7208  0.0143\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# your .log files\n",
    "LOG_DIR = \"*.log\"\n",
    "\n",
    "# regex patterns to capture the values\n",
    "patterns = {\n",
    "    \"auc\": r\"ROC AUC:\\s*([0-9.]+)\",\n",
    "    \"bacc\": r\"Balanced Accuracy:\\s*([0-9.]+)\",\n",
    "    \"sens_spec20\": r\"Spec 20% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec40\": r\"Spec 40% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec60\": r\"Spec 60% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "}\n",
    "\n",
    "# store results\n",
    "results = {k: [] for k in [\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\"]}\n",
    "\n",
    "for log_file in glob.glob(LOG_DIR):\n",
    "    with open(log_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        # extract AUC\n",
    "        auc = re.search(patterns[\"auc\"], text)\n",
    "        if auc:\n",
    "            results[\"auc\"].append(float(auc.group(1)))\n",
    "        # extract balanced accuracy\n",
    "        bacc = re.search(patterns[\"bacc\"], text)\n",
    "        if bacc:\n",
    "            results[\"bacc\"].append(float(bacc.group(1)))\n",
    "        # extract sensitivities at different specificity levels\n",
    "        for key, pat in [(\"sens20\", \"sens_spec20\"), (\"sens40\", \"sens_spec40\"), (\"sens60\", \"sens_spec60\")]:\n",
    "            match = re.search(patterns[pat], text)\n",
    "            if match:\n",
    "                sens = float(match.group(1))  # first number = sensitivity\n",
    "                results[key].append(sens)\n",
    "\n",
    "# summarize into DataFrame\n",
    "summary = {}\n",
    "for metric, values in results.items():\n",
    "    arr = np.array(values, dtype=float)\n",
    "    summary[metric] = {\n",
    "        \"mean\": np.mean(arr),\n",
    "        \"std\": np.std(arr, ddof=1)  # sample std\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(summary).T\n",
    "print(df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log files:\n",
      " - tabpfn_default_seed0.log\n",
      " - tabpfn_default_seed2.log\n",
      " - tabpfn_default_seed12.log\n",
      " - tabpfn_default_seed15.log\n",
      " - tabpfn_default_seed21.log\n",
      "\n",
      "Per-run results (from LAST [TEST] block):\n",
      "                        file  seed     auc    bacc  sens20  sens40  sens60\n",
      "0   tabpfn_default_seed0.log     0  0.7242  0.6541  0.9553  0.8949  0.7114\n",
      "1   tabpfn_default_seed2.log     2  0.7137  0.6643  0.9463  0.8949  0.7181\n",
      "2  tabpfn_default_seed12.log    12  0.7212  0.6642  0.9620  0.9060  0.7047\n",
      "3  tabpfn_default_seed15.log    15  0.7324  0.6663  0.9642  0.8949  0.7293\n",
      "4  tabpfn_default_seed21.log    21  0.7227  0.6653  0.9508  0.8993  0.7181\n",
      "\n",
      "Summary (mean ± std) across seeds:\n",
      "          mean     std\n",
      "auc     0.7228  0.0067\n",
      "bacc    0.6628  0.0050\n",
      "sens20  0.9557  0.0075\n",
      "sens40  0.8980  0.0049\n",
      "sens60  0.7163  0.0091\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# your .log files\n",
    "# LOG_DIR = \"*.log\"\n",
    "log_files = [\n",
    "    \"tabpfn_default_seed0.log\",\n",
    "    \"tabpfn_default_seed2.log\",\n",
    "    \"tabpfn_default_seed12.log\",\n",
    "    \"tabpfn_default_seed15.log\",\n",
    "    \"tabpfn_default_seed21.log\",\n",
    "]\n",
    "\n",
    "# regex patterns to capture the values\n",
    "patterns = {\n",
    "    \"seed\": r\"Running with seed:\\s*(\\d+)\",\n",
    "    \"auc\": r\"ROC AUC:\\s*([0-9.]+)\",\n",
    "    \"bacc\": r\"Balanced Accuracy:\\s*([0-9.]+)\",\n",
    "    \"sens_spec20\": r\"Spec 20% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec40\": r\"Spec 40% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "    \"sens_spec60\": r\"Spec 60% → Sens:\\s*([0-9.]+), Spec:\\s*([0-9.]+), Thr\",\n",
    "}\n",
    "\n",
    "# store results per seed\n",
    "all_results = []\n",
    "\n",
    "print(\"Using log files:\")\n",
    "for f in log_files:\n",
    "    print(\" -\", f)\n",
    "\n",
    "# Regex patterns (handles the unicode arrow \"→\")\n",
    "pat_seed = re.compile(r\"Running with seed:\\s*(\\d+)\")\n",
    "pat_auc = re.compile(r\"ROC AUC:\\s*([0-9.]+)\")\n",
    "pat_bacc = re.compile(r\"Balanced Accuracy:\\s*([0-9.]+)\")\n",
    "pat_spec20 = re.compile(r\"Spec\\s*20%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40 = re.compile(r\"Spec\\s*40%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60 = re.compile(r\"Spec\\s*60%\\s*→\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "# (Optional) fallback patterns if your logs sometimes use \"->\" instead of \"→\"\n",
    "pat_spec20_fallback = re.compile(r\"Spec\\s*20%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec40_fallback = re.compile(r\"Spec\\s*40%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "pat_spec60_fallback = re.compile(r\"Spec\\s*60%\\s*->\\s*Sens:\\s*([0-9.]+),\\s*Spec:\\s*([0-9.]+),\\s*Thr\")\n",
    "\n",
    "def extract_from_last_test_block(text: str):\n",
    "    \"\"\"\n",
    "    Split by '[TEST]' and parse metrics from the last block only.\n",
    "    Returns dict with seed, auc, bacc, sens20/40/60 (sensitivities).\n",
    "    \"\"\"\n",
    "    parts = re.split(r\"\\[TEST\\]\", text)\n",
    "    last_block = parts[-1] if parts else text  # if no [TEST], use whole text\n",
    "\n",
    "    # get seed from anywhere in file (first occurrence)\n",
    "    seed_m = pat_seed.search(text)\n",
    "    seed = int(seed_m.group(1)) if seed_m else None\n",
    "\n",
    "    # pull metrics from the last block\n",
    "    def _grab(pat, block, fallback=None):\n",
    "        m = pat.search(block)\n",
    "        if (not m) and fallback:\n",
    "            m = fallback.search(block)\n",
    "        return m\n",
    "\n",
    "    auc_m = pat_auc.search(last_block)\n",
    "    bacc_m = pat_bacc.search(last_block)\n",
    "\n",
    "    s20_m = _grab(pat_spec20, last_block, pat_spec20_fallback)\n",
    "    s40_m = _grab(pat_spec40, last_block, pat_spec40_fallback)\n",
    "    s60_m = _grab(pat_spec60, last_block, pat_spec60_fallback)\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"auc\": float(auc_m.group(1)) if auc_m else None,\n",
    "        \"bacc\": float(bacc_m.group(1)) if bacc_m else None,\n",
    "        \"sens20\": float(s20_m.group(1)) if s20_m else None,\n",
    "        \"sens40\": float(s40_m.group(1)) if s40_m else None,\n",
    "        \"sens60\": float(s60_m.group(1)) if s60_m else None,\n",
    "    }\n",
    "\n",
    "# Parse all logs\n",
    "rows = []\n",
    "for path in log_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read()\n",
    "    row = {\"file\": path}\n",
    "    row.update(extract_from_last_test_block(txt))\n",
    "    rows.append(row)\n",
    "\n",
    "df_runs = pd.DataFrame(rows)\n",
    "print(\"\\nPer-run results (from LAST [TEST] block):\")\n",
    "print(df_runs)\n",
    "\n",
    "# Summaries\n",
    "summary = {}\n",
    "for metric in [\"auc\", \"bacc\", \"sens20\", \"sens40\", \"sens60\"]:\n",
    "    vals = df_runs[metric].dropna().to_numpy(dtype=float)\n",
    "    if len(vals) == 0:\n",
    "        mean, std = np.nan, np.nan\n",
    "    elif len(vals) == 1:\n",
    "        mean, std = float(vals[0]), np.nan\n",
    "    else:\n",
    "        mean, std = float(np.mean(vals)), float(np.std(vals, ddof=1))\n",
    "    summary[metric] = {\"mean\": mean, \"std\": std}\n",
    "\n",
    "df_summary = pd.DataFrame(summary).T\n",
    "print(\"\\nSummary (mean ± std) across seeds:\")\n",
    "print(df_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
